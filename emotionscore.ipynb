{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!mkdir ~/.kaggle\n!touch ~/.kaggle/kaggle.json\n\napi_token = {\"username\":\"guest5\",\"key\":\"db3d7ebe8dbbb45f2caa63d43a6eb7cd\"}\n\nimport json\n\nwith open('/root/.kaggle/kaggle.json', 'w') as file:\n    json.dump(api_token, file)\n\n!chmod 600 ~/.kaggle/kaggle.json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os, sys\nsys.stdout = open('Output.txt', 'w')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def detect_faces(path):\n    \"\"\"Detects faces in an image.\"\"\"\n    from google.cloud import vision\n    import io, os\n\n    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"../input/apikey/Key.json\"\n\n    client = vision.ImageAnnotatorClient()\n\n    with io.open(path, 'rb') as image_file:\n        content = image_file.read()\n\n    image = vision.Image(content=content)\n\n    response = client.face_detection(image=image)\n    faces = response.face_annotations\n\n    # Names of likelihood from google.cloud.vision.enums\n    likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE', 'LIKELY', 'VERY_LIKELY')\n    flag = 0\n    imageBool = 0\n    # Iterating over faces in image (will be executed only once as there should only be one face in each image)\n    for face in faces:\n        flag = 1\n        d = face.detection_confidence\n        a = likelihood_name[face.anger_likelihood]\n        j = likelihood_name[face.joy_likelihood]\n        su = likelihood_name[face.surprise_likelihood]\n        so = likelihood_name[face.sorrow_likelihood]\n        h = likelihood_name[face.headwear_likelihood]\n        b = likelihood_name[face.blurred_likelihood]\n        u = likelihood_name[face.under_exposed_likelihood]\n        t = face.tilt_angle\n        p = face.pan_angle\n        r = face.roll_angle\n\n        # Exporting values to text file\n        print('Detection confidence:{}'.format(d))\n        print('anger: {}'.format(a))\n        print('joy: {}'.format(j))\n        print('surprise: {}'.format(su))\n        print('sorrow: {}'.format(so))\n        print('headwear: {}'.format(h))\n        print('blurred: {}'.format(b))\n        print('under exposed: {}'.format(u))\n        print('tilt angle: {}'.format(t))\n        print('pan angle: {}'.format(p))\n        print('roll angle: {}'.format(r))\n\n        # Checking if the image meets the critira\n        if d > 0.5 and a == 'VERY_UNLIKELY' and j == 'VERY_UNLIKELY' and su == 'VERY_UNLIKELY' and so == 'VERY_UNLIKELY' and h == 'VERY_UNLIKELY' and b == 'VERY_UNLIKELY' and u == 'VERY_UNLIKELY' and  t < 5 and t > -5 and p < 5 and p > -5 and r < 5 and r > -5:\n            imageBool = 1\n        else:\n            imageBool = 0\n        \n        # Face bounds are not needed, but just in case ¯\\_(ツ)_/¯\n        vertices = (['({},{})'.format(vertex.x, vertex.y)\n                    for vertex in face.bounding_poly.vertices])\n        print('face bounds: {} \\n'.format(','.join(vertices)))\n        break\n\n    # A flag to mark finding at least one face; because some images are so distorted that no face can be detected\n    if flag == 0:\n        # Appending zero for distorted image; in order not to mess the list ordering\n        imageBool = 0\n        print('Detection confidence: 0')\n        print('anger: UNKNOWN')\n        print('joy: UNKNOWN')\n        print('surprise: UNKNOWN')\n        print('sorrow: UNKNOWN')\n        print('headwear: UNKNOWN')\n        print('blurred: UNKNOWN')\n        print('under exposed: UNKNOWN')\n        print('tilt angle: 99')\n        print('pan angle: 99')\n        print('roll angle: 99')\n\n    if imageBool == 1:\n        p = path[29:].strip()\n        !kaggle datasets download niveditjain/human-faces-dataset -f {p}\n        \n    # Error Handling\n    if response.error.message:\n        raise Exception(\n            '{}\\nFor more info on error messages, check: '\n            'https://cloud.google.com/apis/design/errors'.format(\n                response.error.message))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nflag = 0\nfor dirname, _, filenames in os.walk('../input/human-faces-dataset/r1/r1/10'):\n    if flag == 1:\n        break\n    for filename in filenames:\n        i += 1\n        if i == 99:\n            sys.stdout.close()\n            break\n        image = os.path.join(dirname, filename)\n        print(image)\n        detect_faces(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sys.stdout.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#os.remove(\"/kaggle/working/8CHATI4HaRPsBUTse0ijjxZtavsUKufd.jpeg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}